{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\"Генерация текста\"\" с исключением ошибки незнакомых слов",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlN9GslPSFdq"
      },
      "source": [
        "База- диалоги из фильма гениального фильма \"Кин-Дза-Дза\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np #библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11f7bb9-71cb-44f6-ce00-8f6102b44dea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "# **Парсинг данных**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YJwFxHxX7-N"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nROI3csMX97e"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/chatbot.txt\", sep =';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgNwu04BYEqW"
      },
      "source": [
        "data = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZifWixXYHDm",
        "outputId": "48712c20-128e-48db-b28c-790cedde52ad"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['- - Они будут на карачках ползать, а мы на них плевать!'],\n",
              "       ['  - А зачем?'],\n",
              "       ['- - Как зачем удовольствие получать.'],\n",
              "       ...,\n",
              "       ['Скрипач?'],\n",
              "       ['Дядя Вова?'],\n",
              "       ['Скрипач...']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHv8a2yCYL4E"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "for i in range(len(data)): # для каждой пары вопрос-ответ\n",
        "    if i%2==0:\n",
        "      questions.append(data[i]) # то вопросительную реплику отправляем в список вопросов\n",
        "    elif i%2 ==1:\n",
        "      answers.append(data[i]) # а ответную в список ответов\n",
        "answer = []\n",
        "for i in range(len(answers)):\n",
        "  answer.append( '<START> ' + answers[i] + ' <END>' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNUBbyQYOWx"
      },
      "source": [
        "question = []\n",
        "for i in range(len(questions)):\n",
        "  temp = str(questions[i][0])\n",
        "  question.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wV8I6qttYVVH",
        "outputId": "b8d33697-da35-4803-91f7-67c3f2253376"
      },
      "source": [
        "questions[i][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Дядя Вова?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx8MuEP0YRLQ"
      },
      "source": [
        "answers = []\n",
        "for i in range(len(answer)):\n",
        "  temp = str(answer[i][0])\n",
        "  answers.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4mqexvp7YTHq",
        "outputId": "f0b4649d-1e8d-4b05-cd90-520466ff4c62"
      },
      "source": [
        "answer[i][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<START> Скрипач... <END>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_480VcnYaAx"
      },
      "source": [
        "maxWordsCount = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GHfbrINYcD8",
        "outputId": "b8b7abb9-f859-4477-ee17-c7516536f9c2"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token='unknown', char_level=False)\n",
        "tokenizer.fit_on_texts(question + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фрагмент словаря : [('unknown', 1), ('start', 2), ('end', 3), ('а', 4), ('ку', 5), ('не', 6), ('я', 7), ('и', 8), ('в', 9), ('что', 10), ('на', 11), ('ты', 12), ('у', 13), ('это', 14), ('вот', 15), ('ну', 16), ('мы', 17), ('так', 18), ('как', 19), ('нет', 20), ('вы', 21), ('скрипач', 22), ('с', 23), ('то', 24), ('родной', 25), ('он', 26), ('вас', 27), ('нас', 28), ('пацак', 29), ('за', 30), ('есть', 31), ('меня', 32), ('они', 33), ('кц', 34), ('надо', 35), ('ещё', 36), ('давай', 37), ('дядя', 38), ('тут', 39), ('тебя', 40), ('здесь', 41), ('там', 42), ('когда', 43), ('где', 44), ('из', 45), ('владимир', 46), ('николаевич', 47), ('кю', 48), ('тебе', 49), ('только', 50)]\n",
            "Размер словаря : 1989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dARTLR9WaXdl",
        "outputId": "b65a2244-6ee6-417f-da8c-e2621e6d7575"
      },
      "source": [
        "dict_list = []\n",
        "for  i in range(len(vocabularyItems)):\n",
        "   dict_list.append(vocabularyItems[i][0])\n",
        "print(dict_list)\n",
        "print(len(dict_list)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['unknown', 'start', 'end', 'а', 'ку', 'не', 'я', 'и', 'в', 'что', 'на', 'ты', 'у', 'это', 'вот', 'ну', 'мы', 'так', 'как', 'нет', 'вы', 'скрипач', 'с', 'то', 'родной', 'он', 'вас', 'нас', 'пацак', 'за', 'есть', 'меня', 'они', 'кц', 'надо', 'ещё', 'давай', 'дядя', 'тут', 'тебя', 'здесь', 'там', 'когда', 'где', 'из', 'владимир', 'николаевич', 'кю', 'тебе', 'только', 'всё', 'если', 'ы', 'сейчас', 'вова', 'цак', 'же', 'пацаки', 'или', 'мне', 'два', 'кто', 'нам', 'чего', 'нибудь', 'мама', 'все', 'время', 'к', 'да', 'гравицаппу', 'по', 'планеты', 'гедеван', 'вам', 'значит', 'зачем', 'могу', 'она', 'их', 'спасибо', 'до', 'спичку', 'спички', 'раз', 'этот', 'спокойно', 'земля', 'от', 'во', 'пошли', 'может', 'землю', 'пж', 'штаны', 'ясно', 'нельзя', 'сами', 'эцих', 'его', 'бы', 'них', 'эцилопп', 'уэф', 'говорит', 'номер', 'одень', 'но', 'скрипку', 'друг', 'планета', 'сказал', 'гедевану', 'буду', 'такое', 'ыку', 'почему', 'сюда', 'чатланин', 'куда', 'будьте', 'любезны', 'можно', 'уже', 'для', 'привет', 'вовка', 'земле', 'понял', 'извините', 'машкову', 'гравицаппа', 'мозги', 'очень', 'жёлтые', 'делать', 'чатлане', 'э', 'потом', 'би', 'тогда', 'теперь', 'сколько', 'цаппу', 'предложение', 'три', 'пока', 'слушай', 'всем', 'должен', 'чтобы', 'сам', 'нужен', 'перед', 'им', 'пусть', 'давайте', 'ему', 'туда', 'здравствуйте', 'идёт', 'спирали', 'мой', 'хорошо', 'дза', 'щас', 'две', 'ничего', 'луц', 'была', 'люсенька', 'раза', 'приседать', 'зараза', 'товарищ', 'поэтому', 'пожалуйста', 'плюк', 'одного', 'нами', 'должны', 'летим', 'отдай', 'какая', 'макароны', 'тентуре', 'какой', 'эта', 'носок', 'тихо', 'наши', 'показывает', 'ни', 'ак', 'чё', 'быстро', 'пепелац', 'ладно', 'больше', 'скажите', 'плюке', 'господин', 'хватит', 'александрович', 'бандуру', 'родная', 'полетели', 'ка', 'скажи', 'грузинск', 'было', 'тормози', 'речке', 'него', 'кончай', 'ги', 'алё', 'бу', 'пацака', 'господина', 'носить', 'делай', 'деньги', 'планету', 'знают', 'всю', 'человек', 'точку', 'знаешь', 'перемещения', 'какие', 'откуда', 'хочешь', 'та', 'думал', 'семь', 'без', 'эти', 'думай', 'ж', 'нажал', 'свой', 'хотите', 'стой', 'чатла', 'можешь', 'пой', 'дай', 'ыыыы', 'ха', 'тоже', 'говорил', 'твоей', 'тим', 'ваш', 'ыыыыыы', 'её', 'воды', 'будут', 'удовольствие', 'небо', 'имею', 'право', 'передо', 'мной', 'плохо', 'такой', 'уйди', 'отсюда', 'заднее', 'топливо', 'туалет', 'возьмитесь', 'руки', 'веди', 'под', 'решать', 'будем', 'отправления', 'времени', 'решить', 'прошлое', 'родные', 'ге', 'опять', 'коробок', 'скрипача', 'земли', 'навсегда', 'цели', 'система', 'отличник', 'друзья', 'здрасьте', 'секундочку', 'о', 'уэфу', 'кууу', 'тентуру', 'ыы', 'прораб', 'дома', 'стоит', 'новенького', 'снова', 'ыыы', 'пятьдесят', 'этих', 'нравится', 'один', 'говорят', 'пидибидидам', 'сели', 'чатлов', 'заткнись', 'чатлан', 'чтоб', 'нету', 'пидидам', 'ыыыыы', 'хануд', 'воздух', 'жизни', 'мог', 'том', 'играйтесь', 'чем', 'альфе', 'тыщ', 'пожизненный', 'посмотри', 'благо', 'братцы', 'думаете', 'балда', 'чатлы', 'питибидидим', 'питибидидам', 'питибидитибидитибидидам', 'получать', 'такого', 'пацакам', 'надеть', 'малиновые', 'никогда', 'был', 'вместо', 'первый', 'грузинский', 'которую', 'украл', 'бывает', 'языках', 'кем', 'чушь', 'затормозить', 'инопланетянин', 'вашей', 'ноги', 'б', 'возможность', 'переместить', 'свою', 'минут', 'брат', 'полчаса', 'е', 'будет', 'ли', 'будь', 'взглянуть', 'манохина', 'трубы', 'лопнули', 'молодец', 'тобой', 'слушайте', 'домой', 'понимаете', 'остался', 'песок', 'уксус', 'быть', 'планете', 'четыре', 'города', 'открой', 'говорю', 'ль', 'уставился', 'про', 'кин', 'фу', 'купим', 'покажи', 'жена', 'сын', 'пудришь', 'нужны', 'ребята', 'пойдём', 'вполголоса', 'свои', 'жизнь', 'говоришь', 'вода', 'при', 'одна', 'знаете', 'твоё', 'слово', 'купить', 'половиной', 'возьмём', 'сделали', 'равно', 'каппу', 'рации', 'этом', 'играть', 'народу', 'дам', 'отдашь', 'правду', 'гедевана', 'который', 'транклюкатор', 'дайте', 'машковым', 'чатл', 'игра', 'мозгами', 'клетках', 'звери', 'воду', 'женщина', 'моря', 'центра', 'сними', 'делают', 'продают', 'спрашиваю', 'возьми', 'батуми', 'переместились', 'сорок', 'видео', 'генацвале', 'никто', 'поёт', 'пидибидитибидитибидидам', 'сто', 'кого', 'голове', 'одевай', 'сидеть', 'воздуха', 'какое', 'наша', 'альфа', 'конечно', 'хоть', 'дальше', 'даст', 'фигушки', 'машинку', 'перемещаемся', 'гастроном', 'себе', 'другой', 'гвоздями', 'налево', 'большой', 'медведицы', 'кактусы', 'плюкане', 'наших', 'галактики', 'через', 'чужая', 'кажется', 'приветствует', 'своей', 'зелёная', 'уэфа', 'эту', 'лететь', 'шесть', 'какую', 'скрипка', 'смотри', 'быстрее', 'намордниками', 'карачках', 'ползать', 'плевать', 'видело', 'позорного', 'глубоко', 'скорблю', 'приказ', 'намордники', 'радоваться', 'немножко', 'много', 'имеет', 'права', 'бить', 'ночам', 'кончится', 'видел', 'маленький', 'таким', 'меркантильным', 'советовать', 'работать', 'того', 'думать', 'космонавт', 'нобелевскую', 'премию', 'дадут', 'верни', 'ложку', 'нищих', 'артистов', 'лишнее', 'жрёт', 'надень', 'пепелаце', 'сиди', 'продолжения', 'которых', 'знает', 'обманывает', 'некрасиво', 'деньгами', 'оставь', 'тормозную', 'жидкость', 'выпил', 'алкаш', 'одеколон', 'украла', 'раздражай', 'даму', 'каша', 'пластиковая', 'рядом', 'малый', 'филиал', 'оранжереи', 'плюкан', 'неважно', 'наденьте', 'дыхательные', 'аппараты', 'именно', 'имени', 'прошу', 'отпустите', 'абрадокс', 'маску', 'сниму', 'надышу', 'цветение', 'микроклимат', 'покой', 'позавидовать', 'смотрите', 'третий', 'росток', 'наступили', 'порочными', 'всех', 'предоставили', 'либо', 'терять', 'попусту', 'существа', 'антитентуры', 'обязан', 'исходную', 'вернуть', 'момент', 'сможете', 'судьбу', 'выбирайте', 'пущу', '50', 'клеил', 'носком', 'перемещается', 'покажешь', 'отдыхать', 'вылезай', 'вытаскивай', 'записано', 'встретят', 'общества', 'цветовой', 'дифференциации', 'штанов', 'прощаться', 'привык', 'здоров', 'разрешите', 'объекте', 'гуляет', 'хлебом', 'сбегай', 'забыла', 'захвати', 'направо', 'знаем', 'забыли', 'булочной', 'моя', 'галактика', 'машинка', 'нажимать', 'видишь', 'хреновина', 'солнце', 'считать', 'каракумы', 'киндза', 'переместился', 'хочу', 'ночи', 'куу', 'do', 'you', 'speak', 'english', 'парле', 'франсе', 'шпрехен', 'зи', 'денег', 'экскурсовода', 'получилось', 'уж', 'одной', 'in', 'понимаю', 'хотят', 'перебьётся', 'неудобно', 'дзинь', 'язык', 'маймуно', 'веришвило', 'посольство', 'прилетели', 'большая', 'ребят', 'гравицаппы', 'угу', 'кюю', 'машков', 'открытый', 'космос', 'получишь', 'другом', 'кооперативную', 'квартиру', 'заплачено', 'вместе', 'полспички', 'пошутил', 'половину', 'меньше', 'планет', 'гражданочка', 'присесть', 'гляди', 'своим', 'даже', 'галактике', 'дашь', 'никуда', 'тысячи', 'дать', 'рублей', 'копейки', 'коробка', 'зовут', 'вдруг', 'море', 'столько', 'положи', 'дикари', 'полюбил', 'научу', 'инопланетяне', 'штанами', 'фарцуют', 'разворачивай', 'нахрен', 'эцилоппы', 'транклюкирует', 'интерком', 'правительству', 'никого', 'умею', 'подожди', 'играй', 'могли', 'эцилоппа', 'рот', 'уууу', 'абсурд', 'вообще', 'попоём', 'залезайте', 'пляшите', 'всегда', 'юнеско', 'артисты', 'жить', 'наш', 'гадюшник', 'кончился', 'нечестная', 'крутить', 'своими', 'моё', 'дело', 'сидят', 'знаю', 'делаешь', 'катер', 'автомат', 'сделает', 'тидибидидам', 'тидибиди', 'тёплого', 'десять', 'ыыыыыыыыыыыыыыыыыыы', 'жив', 'счастлив', 'удельный', 'вес', 'помню', 'юпитер', 'марс', 'венера', 'место', 'говори', 'этим', 'поняла', 'ржавая', 'ёй', 'странно', 'знал', 'бездействовал', 'приседал', 'перепутал', 'подбрось', 'своего', 'взял', 'ин', 'стоя', 'ыыыыыыы', 'намордниках', 'повернись', 'радуйся', 'нос', 'отдавай', 'сутки', 'брось', 'мешай', 'ночь', 'половина', 'ваша', 'врут', 'спичек', 'молодой', 'эй', 'хотел', 'местная', 'грузинка', 'альфу', 'противогаз', 'обойдутся', 'бережо', 'сообщите', 'ваши', 'координаты', 'деконт', 'переместит', 'всего', 'доброго', 'травке', 'бегаешь', 'горшочке', 'сидишь', 'мужички', 'заразы', 'лучше', 'пст', 'дождавшись', 'скоро', 'принесут', 'одиннадцать', 'вовк', 'закупим', 'зря', 'обычная', 'кнопку', 'пройти', 'старый', 'арбат', 'сдались', 'цапу', 'корыто', 'хуже', 'просто', 'ищи', 'ансамбль', 'балды', 'контрабандный', 'возьмут', 'свидетелях', 'еда', 'девушка', 'действительно', 'людей', 'делаете', 'хороший', 'вопрос', 'нему', 'напрасно', 'беспокоитесь', 'оранжереях', 'прекрасные', 'условия', 'можете', 'продолжать', 'соседство', 'галактикой', 'беда', 'снедаемы', 'страстями', 'продолжение', 'виде', 'вызовем', 'спросим', 'скажут', 'девочка', 'самые', 'умные', 'решили', 'пардон', 'каком', 'другого', 'жми', 'философствовать', 'возникнет', 'почти', 'хотя', 'контакты', 'вернуться', 'вино', 'час', 'мгимо', 'институт', 'сказали', 'сразу', 'пудрить', 'такие', 'положим', 'гравицаппой', 'вселенной', 'пять', 'клади', 'визатор', 'точка', 'потому', 'понимаешь', 'цаки', 'оголтелый', 'расизм', 'твой', 'целую', 'пускают', 'иди', 'останавливает', 'полчатла', 'сынок', 'со', 'тыщу', 'центре', 'коробков', 'давным', 'давно', 'привезём', 'извини', 'забыл', 'живёт', 'строитель', 'сыграй', 'класс', 'говорите', 'клетке', 'никак', 'последний', 'выдох', 'были', 'мои', 'видит', 'соловей', 'пацаком', 'ааахх', 'вагоне', 'кристалл', 'представления', 'плати', 'слушаю', 'одном', 'неё', 'ящика', 'спичка', 'украли', 'поймайте', 'братья', 'планетарии', 'гы', 'дверь', 'месяц', 'эге', 'придет', '11', 'тысяч', 'парнишка', 'сбегает', 'справочную', 'позвонит', 'подождём', 'справочной', 'узм', '247', 'бета', 'пространстве', 'контакт', 'переместиться', 'ведь', 'относительно', 'знать', 'сработала', 'козёл', 'дырочками', 'притяжение', 'пустыне', 'пустыни', 'западе', 'ашхабад', 'приятно', 'виноградный', 'зелень', 'помните', 'назвал', 'тот', 'которого', 'той', 'тапочки', 'остановитесь', 'опаздываешь', 'консерватории', 'учишься', 'банкет', 'тбилиси', 'ага', 'капстрана', 'иностранным', 'владеешь', 'gentlemen', 'sorry', 'we', 'haven’t', 'money', 'now', 'туристы', 'отстали', 'группы', 'подбросьте', 'переводи', 'дойч', 'документы', 'валюта', 'осталось', 'отошли', 'затерялись', 'песках', 'тёплое', 'договорились', 'подбросите', 'быстрей', 'ближайшего', 'доберёмся', 'кофту', 'отдал', 'жестом', 'чирканье', 'коробку', 'буквочки', 'made', 'тюркиш', 'надену', 'тоном', 'каким', 'произносят', 'доволен', 'таки', 'рукой', 'рта', 'пффффи', 'русский', 'потребовалось', 'скрывать', 'советского', 'союза', 'прибыли', 'культурному', 'обмену', 'ищут', 'предоставите', 'связаться', 'нашим', 'посольством', 'крупные', 'неприятности', 'понимаем', 'вставляй', 'африка', '215', 'колокольчик', 'медведица', 'найдутся', 'выкатываете', 'гаража', 'непорядок', 'находит', 'огниво', 'переживая', 'принцип', 'действия', 'огнива', 'задувает', 'огонёк', 'сделаем', 'положите', 'получите', 'матушке', 'город', 'пришелец', 'грузин', 'чатланами', 'помедленнее', 'двоешник', 'поиграем', 'игры', 'весёлые', 'подождите', 'показывай', 'запомни', 'национальность', 'биологический', 'фактор', 'лица', 'других', 'чём', 'друга', 'отличаются', 'небоскрёб', 'пальтишке', 'зябнешь', 'чьто', 'уважения', 'присутствующим', 'дамам', 'поставим', 'проверять', 'ща', 'ас', 'каких', 'условиях', 'представитель', 'цивилизованной', 'требую', 'проследили', 'лексиконом', 'насколько', 'матушку', 'вывезете', 'крутится', 'прощай', 'денутся', 'удавятся', 'триста', 'пятьсот', 'стоят', 'заинтересовался', 'реактором', 'мотор', 'гавриков', 'свяжем', 'курс', 'север', 'средиземное', 'плещется', 'набралось', 'вычеркни', 'берём', 'дорогое', 'определяете', 'послушай', 'скрипачу', 'волнуйся', 'другая', 'катапульта', 'новая', 'испортилась', 'улетел', 'сожгу', 'выловили', 'убить', 'мало', 'связывайся', 'эцилоппами', 'приду', 'проверю', 'сумасшедший', 'смерти', 'ищешь', 'проучив', 'безумного', 'находим', 'местному', 'говорим', 'дают', 'организуем', 'взаимовыгодную', 'торговлю', 'спишь', 'унывай', 'достанем', 'доставали', 'заметил', 'тачанку', 'кричит', 'водительнице', 'тачанки', 'остановись', 'ближе', 'подходи', 'короче', 'скрипке', 'умеет', 'звук', 'сделаю', 'нравица', 'барабанить', 'тыдибидидим', 'пидибидибим', 'пидиби', 'тибиди', 'помешает', 'водички', 'попить', 'взять', 'силой', 'просила', 'чихал', 'вашего', 'закладывает', 'пружинку', 'пляшет', 'вертя', 'бёдрами', 'твоя', 'моргам', 'звонит', 'дурак', 'думает', 'передразнивает', 'мысль', 'весь', 'горький', 'катаклизм', 'наблюдаю', 'рядышком', 'засёк', 'ужасе', 'расплавит', 'полной', 'уверенности', 'дождутся', 'перезарядит', 'газуй', 'скажу', 'довёл', 'фигляр', 'чатланам', 'голову', 'галина', 'борисовна', 'товарищем', 'выступление', 'максимум', 'пол', '2', '200', 'делим', '365', 'вычитаем', 'субботу', 'воскресенье', 'получаем', '6', 'слова', 'минерал', 'гайку', 'приложил', 'объяснительной', 'записке', 'сдал', 'деканат', 'раечке', 'отослала', 'прицепился', 'совесть', 'бедные', 'несчастные', 'голодные', 'плохого', 'преследуете', 'слуха', 'оставьте', 'покое', 'мат', 'второй', 'разряд', 'счёт', 'моих', 'мозгов', 'выигрываете', 'сыграем', 'футляр', 'зубную', 'палку', 'kindermat', 'отдавайте', 'выигрыш', 'начальник', 'довольным', 'смехом', 'похожи', 'всяком', 'случае', 'младшим', 'записал', 'эээ', 'заправимся', 'следующем', 'выступим', 'скидку', 'понятно', 'плакать', 'хочется', 'пальтишки', 'белья', 'смотрит', 'женщину', 'вынули', 'засунули', 'частям', 'продаётся', 'ляд', 'тьфу', 'правый', 'валенок', 'голография', 'куууууууууу', 'побойся', 'неба', 'пластик', 'нормального', 'входа', 'универсам', 'четвёртый', 'насос', 'луца', 'кричат', 'диаметр', 'орбиты', 'дура', 'несчастная', 'вспомнил', 'трубку', 'позвони', 'витьке', 'манохину', 'ключи', 'сантехники', 'вагончике', 'шкафчиком', 'полу', 'лежат', 'соедините', '3', '47', '57', 'аликом', 'сбегали', 'далеко', 'пяти', 'разогреваться', 'готовить', 'ам', 'гайка', 'самая', 'ой', 'люська', 'манохиным', 'пэжем', 'кукукали', 'сообщу', 'твоему', 'начальству', 'транклюкируют', 'паразит', 'алексаныч', 'подарю', 'судье', 'ругал', 'приседали', 'макаки', 'привёз', 'вынул', 'шапки', 'склей', 'песни', 'нажимай', 'пидидим', 'пидиде', 'марусенька', 'белые', 'рубероида', 'оказаться', 'тому', 'моменту', 'тех', 'останется', 'крал', 'кусочек', 'земляне', 'разве', 'еле', 'нашёл', 'память', 'узнал', 'секунда', 'полгода', 'заряда', 'решайте', 'считаю', 'трёх', 'моего', 'маленького', 'сына', 'такая', 'борода', 'выросла', 'клептоманчик', 'свистнул', 'шей', 'фор', 'лав', 'выступаете', 'коленях', 'безобразничай', 'убедившись', 'повиновались', 'докладывает', 'задумчиво', 'напевает', 'уходя', 'стрейнджерс', 'зе', 'радуешься', 'вырубив', 'ударом', 'обращается', 'вперёд', 'бабушка', 'вылезайте', 'поймают', 'ууйй', 'приседает', 'навались', 'нажми', 'куууу', 'заводимся', 'живёте', 'погибли', 'насыпятся', 'дрыгайся', 'попасть', 'трепаться', 'делить', 'вселенную', 'проползли', 'нужно', 'поживи', 'переменится', 'копыта', 'откинешь', 'тем', 'козлом', 'бассейн', 'садаури', 'катапультируете', 'пытаетесь', 'орбите', 'навечно', 'горшке', 'лишний', 'раскрыть', 'лень', 'отравится', 'выключаются', 'разобьются', 'просьба', 'тюремщик', 'двадцать', 'хошь', 'оварищ', 'двоечник', 'твое', 'жёлтыми', 'звони', 'скорую', 'хануидяне', 'нее', 'растения', 'еще', 'вечер', 'позвоню', 'босой', 'простудится', 'пахну', 'холодно', 'железном', 'ящике', 'оденьте', 'нажимаем', 'сработает', 'переместитесь', 'переместим', 'гоби', 'сахара', 'кызылкумы', 'портфеле', 'бутылка', 'живём', 'гадали', 'хрена', 'выясним', 'выбрали', 'направление', 'идём', 'главное', 'добраться', 'звонил', 'аэропорта', 'профессора', 'рогозина', 'шефский', 'концерт', 'давал', 'самолёт', 'положить', 'обед', 'отдам', 'электричку', 'успею', 'иваново', 'учусь', 'текстильном', 'сперва', 'сдавал', 'международных', 'отношений', 'английским', 'французским', 'слабо', 'одночатловую', 'монету', 'шапку', 'зар', 'разы', 'стыдно', 'стало', 'кеце', 'хочет', 'вывези', 'валяй', 'уговорил', 'однорукого', 'закурю', 'разреши', 'типичные', 'марсиане', 'скрываем', 'трудно', 'проникать', 'двух', 'обезьяна', 'осла', 'маймуну', 'бедненькие', 'приехали', 'тс', 'тонкие', 'уши', 'крутятся', 'сатурн', 'поди', 'ту', 'покупать', 'летать', 'любую', 'фьюить', 'секунд', 'свистнули', 'машинки', 'кури', 'довезём', 'сарай', 'ет', 'отвечает', 'оранжевая', 'чатланская', 'купит', 'цемент', 'марки', '300', 'дальтоник', 'зелёный', 'цвет', 'оранжевого', 'отличить', 'турист', 'учил', 'неси', 'посмотрю', 'пытающегося', 'последовать', 'жди', 'уходи', 'специалист', 'гравицаппам', 'покажем', 'моему', 'чатланину', 'проверит', 'горлышко', 'болит', 'остаток', 'этого', 'бутылки', 'бутылок', 'килограмм', 'каши', 'проверяй', 'достать', 'плюнешь', 'этой', 'плюкой', 'простая', 'плюй', 'одну', 'такую', 'фору', 'голубые', 'шрамом', 'оставил', 'центр', 'жадный', 'дешевле', 'любой', 'планетарий', 'выдаст', 'песочком', 'засыпали', 'задней', 'улетят', 'даёшь', 'свистит', 'русские', 'суй', 'дыры', 'обалдел', 'кашу', 'жрали', 'пьёте', 'бандура', 'технику', 'поверит', 'итальянская', 'восемнадцатого', 'века', 'расплачусь', 'цветных', 'металлов', 'сдать', 'новое', 'глаз', 'скатапультировал', 'луцеколонку', 'гедеваа', 'аан', 'скрипа', 'ач', 'деться', 'выкинули', 'ней', 'помощь', 'вызывают', 'надоело', 'парнишку', 'потеряли', 'попадался', 'подобрали', 'принеси', 'песочку', 'иметь', 'правительство', 'держи', 'наготове', 'подвези', 'отработаем', 'дом', 'построим', 'сказала', 'после', 'выступления', 'оо', 'дотронешься', 'прилетит', 'выдернет', 'пепелацем', 'подбросил', 'ящик', 'конкретно', 'думаю', 'правда', 'сидите', 'сказано', 'выступать', 'выпендриваетесь', 'зайдём', 'просит', 'заходи', 'сматываться', 'мальчики', 'толкните', 'телегу', 'подъём', 'гадёныши', 'цело', 'свинец', 'сторону', 'смотреть', 'штрафы', 'эцилоппам', 'минимум', 'день', 'раньше', 'лет', 'доказательства', 'явились', 'космоса', 'продали', 'утверждает', 'профессор', 'рогозин', 'функционировали', 'дискотеке', 'гаграх', 'взрослый', 'проучились', 'семестр', 'исчезли', 'годы', 'давненько', 'встречались', 'думаем', 'проникай', 'настрой', 'понимают', 'хулиган', 'могила', 'кладбище', 'хвастун', 'учился', 'настроение', 'пудрил', 'основу', 'специально', 'ходы', 'куклы', 'результат', 'клетки', 'власть', 'захватили', 'глотка', 'запиши', 'бесплатно', 'даю', 'луцеколонка', 'филонить', 'ракушек', 'реки', 'порядочные', 'люди', 'жалко', 'начальство', 'зарплату', 'повысили', 'давая', 'понять', 'сумма', 'недостаточна', 'задвигая', 'лоток', 'часть', 'пролетим', 'шестьдесят', 'километров', 'правой', 'галоше', 'присядьте', 'узнают', 'присел', 'тссс', 'стоять', 'удовлетворённо', 'тихим', 'голосом', 'дирижабль', 'смертью', 'надышать', 'залезай', 'нормальный', 'чатлами', 'платить', 'адресует', 'чатланке', 'низкое', 'горловое', 'ворчание', 'которое', 'положено', 'издавать', 'ухаживания', 'урр', 'уррр', 'поражается', 'огорчается', 'чатланка', 'отвергла', 'указывает', 'пацаков', 'сидящих', 'чатланском', 'люблю', 'сё', 'отсеке', 'сначала', 'узнать', 'ядра', 'названия', 'лежит', 'стёклышко', 'скрипеть', '013', 'поговорить', 'телефона', 'платит', 'работнице', 'планетария', 'люся', 'слышишь', 'кирилл', 'месте', 'объясню', 'себя', 'чувствует', 'пацачка', 'беги', 'покупай', 'другую', 'найдём', 'гуляй', 'ворюга', 'астронавты', 'которая', 'цаппа', 'ржавое', 'совсем', 'очумели', 'пилотке', 'купят', 'ирту', 'вещь', 'свидетель', 'постам', 'колёсиками', 'нажимал', 'обоим', 'гвоздей', 'выплаты', 'выплата', '500', '250', 'штуку', 'пошутили', 'радость', 'хотели', 'доставить', 'бережочке', 'землянин', 'здравствуй', 'уверен', 'прилетишь', 'москвы', 'алексидзе', 'которые', 'первые', 'ступили', 'гнусные', 'пески', 'задворках', 'новенькая', 'случается', 'пацаку', 'уплетающему', 'разогретый', 'питательный', 'сланец', 'калорийно', 'жмём', 'добываем', 'возвращаемся', 'продаём', 'выкупаем', 'москву', 'хватает', 'обратно', 'погоди', 'войди', 'положение', 'кому', 'траки', 'traki', 'задница', 'вся', 'дрянь', 'пределе', 'слышимости', 'каргис', 'дэда', 'мовткан', 'едрёна', 'мать', 'полке', 'валялось', 'strangers', 'the', 'night', 'пустил', 'ничё', 'денюжки', 'ваше', 'пальто', 'моей', 'шапке', 'голосе', 'сегодня', 'ыыыыыыыыы', 'напели', 'подыми', 'слушаюсь', 'радуюсь', 'пришёл', 'кляп', 'подержи', 'подумаешь', 'последней', 'мыслью', 'чатланской', 'башке', 'кратчайшим', 'путём', 'марш', 'кляпа', 'эцилоппу', 'тюремщику', 'выкатывай', 'предпоследний', 'исчезни', 'гамарджоба', 'убегающего', 'забрав', 'отбежит', 'сторонку', 'стену', 'эциха', 'режь', 'помогите', 'выкатить', 'человечество', 'камушка', 'луны', 'тысячелетия', 'потратило', 'живой', 'неизвестного', 'металла', 'цааааппу', 'очухаются', 'родили', 'фига', 'транклюкировали', 'гастролях', 'успели', 'над', 'головой', 'маячили', 'маму', 'кармане', 'четвереньках', 'соблазнительно', 'закрывается', 'антитентуре', 'долететь', 'можем', 'везло', 'узнали', 'верьте', 'везите', 'шути', 'кислорода', 'процента', 'нормы', 'гедеванико', 'швило', 'гедеванчик', 'акхаури', 'паршивый', 'sit', 'down', 'разговариваешь', 'пацакская', 'повтори', 'затормозишь', 'перемещать', 'прижать', 'снизу', 'пальцем', 'осталась', 'талдычить', 'об', 'милые', 'хорошие', 'закройте', 'видеть', 'тошнит', 'выключи', 'рога', 'огда', 'прошлый', 'ханудяне', 'растений', 'придёт']\n",
            "1988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOJ_dtsUZGQ9",
        "outputId": "87c796a1-f982-48ed-d0b9-fe74453d192f"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(question) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = paddedQuestions\n",
        "print('Пример оригинального вопроса на вход : {}'.format(question[50])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[50])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход :   - Вот ты и покажешь.\n",
            "Пример кодированного вопроса на вход : [ 15  12   8 594   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0]\n",
            "Размеры закодированного массива вопросов на вход : (578, 42)\n",
            "Установленная длина вопросов на вход : 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3vmpKmbZLAx"
      },
      "source": [
        "encoderForInput = encoderForInput[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKhlSWRRZOOd",
        "outputId": "be8c7e63-aed5-4d6a-a310-00ad95e84992"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = paddedAnswers # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[50])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[50][:30])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> - - Пусть еще что-нибудь даст. <END>\n",
            "Пример раскодированного ответа на вход : [   2  156 1448   10   65  464    3    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "Размеры раскодированного массива ответов на вход : (578, 47)\n",
            "Установленная длина ответов на вход : 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvY5NCqPZRDd"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yifVqUFCZS5T",
        "outputId": "f7ee1ba2-2bf7-42cb-82fe-1a49449ccf94"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[50][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[50][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [   2  156 1448   10   65  464    3    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (578, 47, 1989)\n",
            "Установленная длина вопросов на выход : 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "# **Параметры нейросети и модель обучения**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "775a59d4-06e2-40d0-9a3a-355f00cbafef"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    397800      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 200)    397800      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  320800      embedding_3[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1989)   399789      lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,836,989\n",
            "Trainable params: 1,836,989\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeef8044-0de5-4c6f-d95c-96d193ecc174"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=5, epochs=100) \n",
        "# model.save( '/content/drive/My Drive/Предобученные сети/model_100epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "116/116 [==============================] - 12s 14ms/step - loss: 1.1332\n",
            "Epoch 2/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 1.0100\n",
            "Epoch 3/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.8887\n",
            "Epoch 4/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.9454\n",
            "Epoch 5/100\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.9048\n",
            "Epoch 6/100\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.8481\n",
            "Epoch 7/100\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.7936\n",
            "Epoch 8/100\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.8128\n",
            "Epoch 9/100\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.8162\n",
            "Epoch 10/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.7798\n",
            "Epoch 11/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.7110\n",
            "Epoch 12/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.7880\n",
            "Epoch 13/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6814\n",
            "Epoch 14/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6868\n",
            "Epoch 15/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6372\n",
            "Epoch 16/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6513\n",
            "Epoch 17/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6281\n",
            "Epoch 18/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.6510\n",
            "Epoch 19/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5638\n",
            "Epoch 20/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5374\n",
            "Epoch 21/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5755\n",
            "Epoch 22/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5506\n",
            "Epoch 23/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5298\n",
            "Epoch 24/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.5216\n",
            "Epoch 25/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.4650\n",
            "Epoch 26/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.4447\n",
            "Epoch 27/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.4025\n",
            "Epoch 28/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.4097\n",
            "Epoch 29/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.4273\n",
            "Epoch 30/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3615\n",
            "Epoch 31/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3918\n",
            "Epoch 32/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3270\n",
            "Epoch 33/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3372\n",
            "Epoch 34/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3066\n",
            "Epoch 35/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.3083\n",
            "Epoch 36/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2682\n",
            "Epoch 37/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2580\n",
            "Epoch 38/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2545\n",
            "Epoch 39/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2238\n",
            "Epoch 40/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2268\n",
            "Epoch 41/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2101\n",
            "Epoch 42/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1952\n",
            "Epoch 43/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.2089\n",
            "Epoch 44/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.1915\n",
            "Epoch 45/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1703\n",
            "Epoch 46/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1637\n",
            "Epoch 47/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1502\n",
            "Epoch 48/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1469\n",
            "Epoch 49/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1482\n",
            "Epoch 50/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1320\n",
            "Epoch 51/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1239\n",
            "Epoch 52/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1133\n",
            "Epoch 53/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.1132\n",
            "Epoch 54/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0891\n",
            "Epoch 55/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0978\n",
            "Epoch 56/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0894\n",
            "Epoch 57/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0770\n",
            "Epoch 58/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0762\n",
            "Epoch 59/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0720\n",
            "Epoch 60/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0759\n",
            "Epoch 61/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0634\n",
            "Epoch 62/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0601\n",
            "Epoch 63/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0543\n",
            "Epoch 64/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0469\n",
            "Epoch 65/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0445\n",
            "Epoch 66/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0472\n",
            "Epoch 67/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0441\n",
            "Epoch 68/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0378\n",
            "Epoch 69/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0357\n",
            "Epoch 70/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0325\n",
            "Epoch 71/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0293\n",
            "Epoch 72/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0279\n",
            "Epoch 73/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0265\n",
            "Epoch 74/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0258\n",
            "Epoch 75/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0252\n",
            "Epoch 76/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0224\n",
            "Epoch 77/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0242\n",
            "Epoch 78/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0221\n",
            "Epoch 79/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0189\n",
            "Epoch 80/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0215\n",
            "Epoch 81/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0197\n",
            "Epoch 82/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0200\n",
            "Epoch 83/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0178\n",
            "Epoch 84/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0192\n",
            "Epoch 85/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0157\n",
            "Epoch 86/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0163\n",
            "Epoch 87/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0151\n",
            "Epoch 88/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0130\n",
            "Epoch 89/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0146\n",
            "Epoch 90/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0131\n",
            "Epoch 91/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0134\n",
            "Epoch 92/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0137\n",
            "Epoch 93/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0120\n",
            "Epoch 94/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0123\n",
            "Epoch 95/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0116\n",
            "Epoch 96/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0127\n",
            "Epoch 97/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0122\n",
            "Epoch 98/100\n",
            "116/116 [==============================] - 2s 15ms/step - loss: 0.0114\n",
            "Epoch 99/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0106\n",
            "Epoch 100/100\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19ee081e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEHzJjlRYK5-"
      },
      "source": [
        "model.compile(optimizer=Adadelta(), loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rPD8f5tY4up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e99e905-76e0-4ba3-da73-f711b2da72f9"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=5, epochs=50) \n",
        "# model.save( '/content/drive/My Drive/Предобученные сети/model_100epochs(rms) + 50(ada).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0093\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0093\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 2s 13ms/step - loss: 0.0092\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 2s 13ms/step - loss: 0.0092\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 2s 14ms/step - loss: 0.0092\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 1s 13ms/step - loss: 0.0092\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 1s 12ms/step - loss: 0.0092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19a6b97208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_U_rY8UiRL2"
      },
      "source": [
        "# **Подготовка и запуск рабочей нейросети с генерацией ответов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  # for word in words:\n",
        "  #   if words in dict_list:\n",
        "  #     continue\n",
        "  #   else:  \n",
        "  #     words == 'unknown'\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    if word in dict_list:\n",
        "      tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "    # else:\n",
        "    #   # tokensList.append(tokenizer.word_index['unknown'])  \n",
        "    #   continue\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7c913f-6577-4d9c-e33a-cb3702dcb219"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем модель\n",
        "######################\n",
        "\n",
        "encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(10): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : привет\n",
            " как жизнь чего новенького на плюке \n",
            "Задайте вопрос : ну на плюке все нормально,зима,родной\n",
            " вот ты а вот гравицаппа ку \n",
            "Задайте вопрос : а зачем нужна гравицапа\n",
            " ну ку \n",
            "Задайте вопрос : что такое\n",
            " ну ыыыыы нас \n",
            "Задайте вопрос : расскажи историю\n",
            " а ты паршивый чатлан цак одень и sit down когда с пацаком разговариваешь хануд пацакская планета родной \n",
            "Задайте вопрос : вот как заговорил значит\n",
            " я не в \n",
            "Задайте вопрос : не в чем\n",
            " номер своего ку \n",
            "Задайте вопрос : я не знаю\n",
            " пока пацаки \n",
            "Задайте вопрос : ну до свидания\n",
            " сколько ты нам дашь если мы тебя туда положим \n",
            "Задайте вопрос : нисколько,это бесплатно\n",
            " ну что давай прощаться привык я к вам что ли \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhu067toXGQ"
      },
      "source": [
        "# **Загрузка и запуск предобученной модели**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uAayUvUgbyt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ngvBy5yrY3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa9e4985-e9f3-4e16-8ace-2a2d025bf70d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Lg3eOVqKyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e91904-8e1d-4750-d22f-d253fb40b29b"
      },
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "# model = load_model('/content/gdrive/My Drive/Предобученные сети/model_100epochs(rms) + 50(ada).h5')\n",
        "#model = load_model('model_chatbot_100epochs(rms)+50(ada) (1).h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    397800      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 200)    397800      input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  320800      embedding_3[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1989)   399789      lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,836,989\n",
            "Trainable params: 1,836,989\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEfb58cXqsKi"
      },
      "source": [
        "######################\n",
        "# Устанавливаем связи между слоями рабочей модели и предобученной\n",
        "######################\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0]   # входом энкодера рабочей модели будет первый инпут предобученной модели(input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбединг слои(model.layers[2] это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обуч.модели и даем энкодеру(lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # ложим забранные состояния в состояния энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель\n",
        "\n",
        "  decoderInputs = model.input[1]   # входом декодера рабочей модели будет второй инпут предобученной модели(input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбединг слои(model.layers[3] это embedding_2)\n",
        "  decoderLSTM = model.layers[5] # связываем LSTM слои(model.layers[5] это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои(model.layers[6] это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpsqjakx2rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a138be6-d3ec-409d-8ae3-25d01d1a76a7"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : привет \n",
            " как жизнь чего новенького на плюке end\n",
            "Задайте вопрос : все хорошо, а как у вас?\n",
            " ку end\n",
            "Задайте вопрос : и тебе ку\n",
            " ку end\n",
            "Задайте вопрос : ладно,давай расскажи что-то новенькое\n",
            " ну что давай прощаться привык я к вам что ли end\n",
            "Задайте вопрос : плохо дело,переобучился ты что ли\n",
            " вот в туалет end\n",
            "Задайте вопрос : только не сеййчас \n",
            " посмотри end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4AAcX00Rgjb"
      },
      "source": [
        "Вывод: данные для обучения  не были должным образом сформированы(тут диалог более,чем 2х людей, цитаты расположены в примерном порядке их следования в фильме, не всегда там реально вопрос-ответ). Очень интересно сделать такую базу по-правильному и обучить чатбота отвечать в стиле Кин-дза-дза.\n"
      ]
    }
  ]
}